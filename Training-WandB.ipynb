{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xY6R6dTEd06q"},"outputs":[],"source":["#!pip install python-binance -qq\n","#!pip install -qq wandb\n","#!conda install -c conda-forge sktime-all-extras -y\n","#!pip install sktime\n","#!pip install -qq --upgrade tsfresh\n","#!pip install scipy==1.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7U2FOxYgAgU"},"outputs":[],"source":["#!pip install --upgrade protobuf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZW9e1Vmd0_Q","outputId":"abecef36-7152-47d6-edb7-a42be274089c"},"outputs":[{"name":"stdout","output_type":"stream","text":["name, driver_version, memory.total [MiB]\n","NVIDIA GeForce GTX 1050 Ti, 470.103.01, 4036 MiB\n"]}],"source":["!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1D5plb4NeAFS","outputId":"51dea85d-08ee-4df7-8250-83ada891202d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found GPU at: /device:GPU:0\n"]}],"source":["#%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"markdown","metadata":{"id":"6b4INnH3eAfq","tags":[]},"source":["## **Preliminaries** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnPnnBxtd1Bu"},"outputs":[],"source":["import math\n","import numpy as np\n","#from numba import cuda\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import norm\n","from matplotlib.pyplot import figure\n","import statistics\n","\n","from keras.layers import Dropout\n","from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n","#from tqdm.notebook import tqdm\n","\n","#Importing the Libraries\n","%matplotlib inline\n","import matplotlib. pyplot as plt\n","import matplotlib\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.layers import LSTM, Dense, Dropout\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.dates as mandates\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn import linear_model\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import keras.backend as K\n","from keras.callbacks import EarlyStopping\n","#from keras.optimizers import adam_v2, adamax_v2, adadelta_v2, adagrad_v2, rmsprop_v2\n","from keras.optimizers import Adam, Adamax, Adadelta, Adagrad\n","from keras.models import load_model\n","from keras.layers import LSTM, GRU, Flatten,BatchNormalization\n","from tensorflow.keras import regularizers\n","from keras.utils.vis_utils import plot_model\n","import keras\n","import pickle\n","\n","#import tsfresh\n","#from tsfresh import extract_features, extract_relevant_features, select_features\n","#from tsfresh.utilities.dataframe_functions import impute\n","#from tsfresh.feature_extraction import ComprehensiveFCParameters\n","#from tsfresh.feature_extraction.settings import Feature_Extraction_Settings\n","#from sktime.transformers.series_as_features.summarize import TSFreshFeatureExtractor\n","\n","from sklearn.metrics import classification_report, recall_score, precision_score\n","\n","#from statsmodels.tsa.stattools import grangercausalitytests\n","from sklearn.metrics import classification_report\n","from datetime import datetime\n","\n","from IPython.display import clear_output \n","from scipy import signal\n","from sklearn.metrics import classification_report, recall_score, precision_score\n","\n","from sktime.forecasting.model_selection import temporal_train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.decomposition import PCA\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","\n","import wandb\n","#from wandb.keras import WandbCallback\n","\n","from IPython.display import clear_output\n","from sklearn.decomposition import PCA\n","#from keras_tqdm import TQDMNotebookCallback"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2EFiYywOeKu7"},"outputs":[],"source":["root = '/content/drive/MyDrive/'\n","path = root+'generate_dataset/movement/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lEBc7MhioGj"},"outputs":[],"source":["#path = '/home/kurniawan/jupyter/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kn7GLsbdLi25"},"outputs":[],"source":["def dataset_timesteps(dataset, look_back=0):\n","    dataset = dataset.tolist()\n","    dataset_final = []\n","    temp_list = []\n","    temp_list.append(dataset)\n","    \n","    for lb in range( look_back ):\n","        temp = [ 0 for x in range(lb+1) ]\n","        temp_list.append( temp + dataset )\n","    \n","    for idx in range( len(dataset) ):\n","        temp = []\n","        for ls in range( len(temp_list) ):\n","            temp.append( temp_list[ls][idx] )\n","        dataset_final.append(temp)\n","         \n","    return np.array( dataset_final[look_back:] )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dk1xhORyT01"},"outputs":[],"source":["def read_dataset(target, features, nPca, look_back, sqr, train, tes):\n","\n","    df = pd.read_csv(path+\"dataset/ETHBUSD-15m-data.csv\", parse_dates=['timestamp'])\n","    del df['close_time']\n","    del df['quote_av']\n","    del df['tb_base_av']\n","    del df['tb_quote_av']\n","    del df['ignore']\n","\n","    # target\n","    df['target'] = df[target].shift(-1)\n","\n","    # volume / trades\n","    vt_mult = 1\n","    df['vt'] = ( df['volume']/df['trades'] ) * vt_mult\n","    #del df['trades']\n","    #del df['volume']\n","\n","    # precentage change\n","    pct_mult = 2500\n","    df['pct_change'] = df['close'].pct_change(1)\n","    df['target_pct_change'] = df['target'].pct_change(1)\n","    df.dropna(inplace=True)\n","\n","    # movement\n","    fee = 0.0016\n","    move_mult = 1000\n","    df['move'] = df['pct_change'].apply(lambda x: 1 if x > fee else 0)\n","    df['target_move'] = df['target_pct_change'].apply(lambda x: 1 if x > fee else 0)\n","    df['move'] = df['move'] * move_mult\n","\n","    # profit\n","    df['profit'] = df['pct_change'] - fee\n","\n","    # squared\n","    df['open'] = df['open']\n","    df['high'] = df['high']\n","    df['low'] = df['low']\n","    df['close'] = df['close']\n","\n","    df['vt'] = df['vt'] \n","    df['pct_change'] = df['pct_change']\n","    df['move'] = df['move']\n","    df['profit'] = df['profit']\n","\n","    # slice\n","    timeframe_day = int(( 60 / 15 ) * 24)\n","    timeframe = int( timeframe_day * train) +2 +look_back + int( timeframe_day * tes) \n","    df = df.iloc[-(timeframe): -2]\n","    df.dropna(inplace=True)\n","    df.reset_index(inplace=True)\n","    del df['index']\n","\n","    pca = PCA(n_components=nPca)\n","    principalComponents = pca.fit_transform(df[features])\n","    #df['pca'] = principalComponents\n","\n","    if nPca != 0:\n","      feat = pd.DataFrame( principalComponents )\n","    else:\n","      feat = pd.DataFrame( principalComponents )\n","    \n","    feat = feat ** sqr\n","    \n","    from sklearn import preprocessing\n","\n","    x = feat.values #returns a numpy array\n","    min_max_scaler = preprocessing.MinMaxScaler()\n","    x_scaled = min_max_scaler.fit_transform(x)\n","    feat = pd.DataFrame(x_scaled)\n","\n","    #return df\n","\n","    y_train, y_test, x_train, x_test = temporal_train_test_split(y = (df['target'].values),\n","                                                              X = ( df[features].values ),\n","                                                              test_size = (timeframe_day * tes) +1 ) \n","\n","\n","    x_train = dataset_timesteps(x_train, look_back=look_back)\n","    x_test = dataset_timesteps(x_test, look_back=look_back)\n","\n","\n","    y_train = y_train[look_back:]\n","    y_test = y_test[look_back:]\n","\n","    x_train = np.array(x_train.tolist())\n","    x_test = np.array(x_test.tolist())\n","\n","\n","    #x_train = df[features].values[:-(timeframe_day * 7)]\n","    #y_train = df['target'].values[:-(timeframe_day * 7)]\n","\n","    #x_test = df[features].values[-(timeframe_day * 7):]\n","    #y_test = df['target'].values[-(timeframe_day * 7):]\n","\n","    # reshape input to be [samples, time steps, features]\n","    x_train = np.reshape(x_train, (x_train.shape[0], (look_back+1), len(features)))\n","    x_test = np.reshape(x_test, (x_test.shape[0], (look_back+1), len(features) ))\n","\n","    \n","    return x_train, x_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USJZjuhzNx3W"},"outputs":[],"source":["def init_model(x_train, mode, nodes, bias, dropout, flatten, activation, regularizer, layer):\n","  #nodes = 80\n","  #bias = True\n","  #nodes = config.nodes\n","\n","  model = Sequential()\n","\n","  if mode == 'GRU':\n","      model.add(GRU(nodes, input_shape=(x_train.shape[1], x_train.shape[2]), use_bias=bias, activation = activation, \n","                    return_sequences=True,  activity_regularizer=regularizer))  \n","      if dropout != 0: model.add(Dropout(dropout))\n","      for lay in range(layer):\n","          model.add(GRU(int(nodes), use_bias=bias, activation = activation, return_sequences=True, activity_regularizer=regularizer))\n","          if dropout != 0: model.add(Dropout(dropout))\n","\n","    \n","  elif mode == 'LSTM':\n","      model.add(LSTM(nodes, input_shape=(x_train.shape[1], x_train.shape[2]), use_bias=bias, activation = activation, \n","                    return_sequences=True,  activity_regularizer=regularizer))\n","      if dropout != 0: model.add(Dropout(dropout))\n","      for lay in range(layer):\n","          model.add(LSTM(int(nodes), use_bias=bias, activation = activation, return_sequences=True, activity_regularizer=regularizer))\n","          if dropout != 0: model.add(Dropout(dropout))\n","      \n","\n","  if flatten == True:\n","    model.add(Flatten())\n","    if dropout != 0: model.add(Dropout(dropout))\n","    \n","  model.add(Dense(int(nodes),  use_bias=bias, activation = activation, activity_regularizer=regularizer))\n","  if dropout != 0: model.add(Dropout(dropout))\n","  model.add(Dense(int(nodes*0.8),  use_bias=bias, activation = activation, activity_regularizer=regularizer))\n","  if dropout != 0: model.add(Dropout(dropout))\n","  model.add(Dense(int(nodes*0.6),  use_bias=bias, activation = activation, activity_regularizer=regularizer))\n","  if dropout != 0: model.add(Dropout(dropout))\n","  model.add(Dense(int(nodes*0.4),  use_bias=bias, activation = activation, activity_regularizer=regularizer))\n","  if dropout != 0: model.add(Dropout(dropout))\n","  model.add(Dense(int(nodes*0.2),  activation = activation, activity_regularizer=regularizer))\n","  if dropout != 0: model.add(Dropout(dropout))\n","  model.add(Dense(int(nodes*0.1),  activation = activation, activity_regularizer=regularizer))\n","  if dropout != 0: model.add(Dropout(dropout))\n","  model.add(Dense(1, use_bias=bias, activation = activation, activity_regularizer=regularizer))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpIvUh4jX77z"},"outputs":[],"source":["def get_profit(y, y_pred, pct_profit):\n","  fee = 0.0016\n","  eval = pd.DataFrame(y, columns = ['actual'])\n","  eval['pred'] = y_pred\n","  #eval['pred'] = eval['pred'].shift(-1)\n","  #eval.dropna(inplace=True)\n","  #print(len(y), len(y_pred))\n","\n","  # get moe\n","  moe = 0 \n","  for i, row in eval.iterrows():\n","    moe += row['actual'] - row['pred']\n","  moe = moe/len(eval)\n","  eval['pred_moe'] = eval['pred'] + moe\n","\n","  # get percentage change\n","  eval['actual_pct_change'] = eval['actual'].pct_change(1)\n","  eval['pred_pct_change'] = eval['pred'].pct_change(1)\n","  eval['pred_moe_pct_change'] = eval['pred_moe'].pct_change(1)\n","  eval.dropna(inplace=True)\n","  #print(eval[:5])\n","\n","  # get movement\n","  eval['actual_move'] = eval['actual_pct_change'].apply(lambda x: 1 if x>fee else 0)\n","  eval['pred_move'] = eval['pred_pct_change'].apply(lambda x: 1 if x>fee else 0)\n","  eval['pred_moe_move'] = eval['pred_moe_pct_change'].apply(lambda x: 1 if x>fee else 0)\n","\n","  # percentage change - fee\n","  eval['actual_profit'] = eval['actual_pct_change'].apply(lambda x: x - fee)\n","  eval['pred_profit'] = eval['pred_pct_change'].apply(lambda x: x - fee)\n","  eval['pred_moe_profit'] = eval['pred_moe_pct_change'].apply(lambda x: x - fee)\n","\n","  # sum profit\n","  profit = eval[eval[pct_profit]==1]\n","  init_asset = 100\n","  asset = 0\n","  for i, row in profit.iterrows():\n","    asset += init_asset * row['actual_profit']\n","  print(profit[:3])\n","\n","  profit = eval[eval['actual_move']==1]\n","  init_asset = 100\n","  actual_asset = 0\n","  for i, row in profit.iterrows():\n","    actual_asset += init_asset * row['actual_profit']\n","\n","  # diff\n","  diff = 0\n","  for i, row in eval.iterrows():\n","    if row['actual_move'] == row['pred_move']:\n","      diff += 1\n","    else:\n","      diff += 0\n","\n","  actual_diff = len(eval)\n","\n","  # recall\n","  try:\n","    recall = recall_score(eval['actual_move'], eval['pred_move'], pos_label = 1 )\n","  except:\n","    recall = 0\n","\n","  plt.plot(eval['actual'], label='actual')\n","  plt.plot(eval['pred_moe'], label='pred_moe')\n","  plt.legend(loc='best')\n","  plt.show()\n","    \n","  if (asset/init_asset)*100 != 0 and (asset/init_asset)*100 > 0:\n","    for i, row in eval.iterrows():\n","        wandb.log( { 'actual': row['actual'],\n","                   'pred_moe': row['pred_moe'],\n","                   'index_plt': i\n","                   } )\n","\n","  return (actual_asset/init_asset)*100, (asset/init_asset)*100, recall, moe, actual_diff, diff"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vo9Tr7CTU_Tu"},"outputs":[],"source":["def init_callbacks(initial_lr, epochs, lr_decay, monitor):\n","  from tqdm.keras import TqdmCallback\n","\n","  filepath = path+\"weight/\"+str(wandb.run.name)+\"-weight.hdf5\"\n","  checkpoint = ModelCheckpoint(filepath, monitor=monitor, verbose=0, save_best_only=True, mode='auto')\n","\n","  if lr_decay != 0:\n","    initial_learning_rate = initial_lr\n","    epochs = epochs\n","    decay = initial_learning_rate / (epochs/lr_decay)\n","    def lr_time_based_decay(epoch, lr):\n","      return lr * 1 / (1 + decay * epoch)\n","    callbacks_list = [checkpoint,\n","                    LearningRateScheduler(lr_time_based_decay, verbose=0),\n","                    TqdmCallback()\n","                   ] \n","  else:\n","    callbacks_list = [checkpoint,\n","                    TqdmCallback()\n","                   ] \n","\n","  return callbacks_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNtPkurTurfI"},"outputs":[],"source":["def train(retry = 0): \n","  \n","  # wandb\n","  hyperparams = dict(\n","    nodes=80,\n","    lr=0.001      \n","    )\n","  wandb.init(project=\"my-test-project\", entity=\"codechrl\", config=hyperparams)\n","  config = wandb.config\n","  \n","  # dataset\n","  features = ['open']\n","  target = ['close']\n","\n","  features = config.features\n","\n","  while True:\n","    #df = read_dataset(target, features)\n","    x_train, x_test, y_train, y_test = read_dataset(target, features, config.pca, config.look_back, config.sqr, config.train, config.tes)\n","    #print(x_train[:1])\n","    if len(x_train) != 0: break\n","  \n","\n","  # init model\n","  tf.get_logger().setLevel('ERROR')\n","  model = init_model(x_train, config.mode, config.nodes, \n","                     config.bias, config.dropout, config.flatten, \n","                     config.activation, config.regularizer,\n","                    config.layer)\n","\n","  #init_weights = model.get_weights()\n","\n","  # callbacks\n","  callbacks_list = init_callbacks(config.initial_lr, \n","                                  config.epochs, \n","                                  config.lr_decay,\n","                                  config.monitor)\n","\n","  # compile model\n","  \n","  model.compile(loss = config.loss_func, optimizer = config.optimizer)\n","\n","  # fit\n","\n","  #try:\n","  model.fit(x_train, y_train,\n","              validation_data=(x_test, y_test),\n","              epochs = config.epochs, \n","              batch_size = config.batch_size,\n","              verbose = 0, \n","              shuffle = False,\n","              callbacks = callbacks_list,)\n","\n","    #train(retry=retry)\n","    \n","  # eval\n","  # load model\n","  filepath = path+\"weight/\"+str(wandb.run.name)+\"-weight.hdf5\"\n","  model = load_model(filepath)\n","\n","  # predict\n","  y_pred = model.predict(x_test)\n","  print( 'train ', x_train[:2] )\n","  #print('test ', y_test[:2])\n","  #print('pred ',y_pred[:2])\n","  y_pred = [x[0] for x in y_pred]\n","  print('pred ',y_pred[:2])\n","\n","  # profitability\n","  actual_profit, profit, recall, moe, actual_diff, diff = get_profit(y_test, y_pred, config.pct_profit)\n","  difference = ( diff / actual_diff if actual_diff!=0 else 0 )\n","\n","  print(actual_profit, profit)\n","     \n","  if profit <= 0 and retry!=2:\n","    print('RETRY')\n","    train(retry=retry+1)\n","    del model, callbacks_list, filepath, y_pred, \n","    actual_profit, profit, recall, moe, \n","    actual_diff, diff, difference,\n","    x_train, x_test, y_train, y_test \n","    \n","  elif profit <= 0 and retry==2:\n","    #clear_output()\n","    # log into wandb  \n","    pr = (-100/(profit-0.0001))/10000000\n","    wandb.log( { 'retry': retry+1,\n","              'profit': profit,\n","              'moe': abs(moe),\n","              'recall': recall,\n","              'diff': difference,\n","              #'init_weights': init_weights,\n","              'hm': statistics.harmonic_mean( [ pr, recall, difference ] )\n","              } )\n","\n","  else:\n","    # log into wandb  \n","    wandb.log( { 'retry': retry+1,\n","              'profit': profit,\n","              'moe': abs(moe),\n","              'recall': recall,\n","              'diff': difference,\n","              #'init_weights': init_weights,\n","              'hm': statistics.harmonic_mean( [ profit/actual_profit, recall, difference ] )\n","              } )\n","\n","  #if int(str(wandb.run.name)[-1]) % 5 == 0: \n","  clear_output()\n","    \n","  #if profit > 0:\n","  #    del model, callbacks_list, filepath, y_pred, actual_profit, profit, recall, moe, actual_diff, diff, difference, init_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"su2Z21pn8MMO"},"outputs":[],"source":["import itertools\n","list_features = []\n","stuff =  ['open', 'high', 'low', 'close', 'trades', 'volume', 'vt', 'pct_change', 'move' , 'profit']\n","for L in range(0, len(stuff)+1):\n","    for subset in itertools.combinations(stuff, L):\n","        list_features.append( list(subset) )\n","\n","list_features = list_features[1:]\n","#list_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mp88LfuKdFDN"},"outputs":[],"source":["sweep_config = {\n","    'method': 'bayes',         \n","    'metric': {\n","        'name': 'hm',     \n","        'goal': 'maximize'      \n","    },\n","    'parameters': {\n","        \n","        'mode': { \n","          'values' : ['LSTM', 'GRU']\n","        },\n","        \n","        'dropout': { \n","          'values' : [0.0001,  0.01, 0.1, 0.15, 0.2, 0.5]\n","        },\n","        \n","        'flatten': { \n","          'values' : [True]\n","        },\n","        \n","        'regularizer': { \n","          'values' : ['l1', 'l2', 'l1_l2']\n","        },\n","        \n","        'look_back': { \n","          'values' : [0,1,2,3,4,8,16, 24]\n","        },\n","        \n","        'bias': { \n","          'values' : [True, False]\n","        },\n","        \n","        'activation': { \n","          'values' : ['elu', 'relu']\n","        },\n","        \n","        'initial_lr': {\n","          'values' : [0.1, 0.01, 0.001, 0.0001]\n","        },\n","\n","        'epochs': {\n","          'values' : [50, 100, 500, 1000]\n","        },\n","\n","        'lr_decay': {\n","          'values' : [0, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10] \n","        },\n","\n","        'loss_func': {\n","          'values' : ['mean_squared_error', 'mean_squared_error', 'huber_loss', 'mean_absolute_percentage', 'mean_squared_logarithmic', 'cosine_similarity', 'log_cosh' ]\n","        },\n","\n","        'optimizer': {\n","          'values' : [ 'adam', 'adagrad', 'nadam', 'sgd', 'rmsprop', 'adadelta', 'ftrl', 'adamax'  ]\n","        },\n","\n","        'batch_size': {\n","          'values' : [ int(96*7*0.25) ]\n","        },\n","\n","        'pca': {\n","          'values' : [ 1 ]\n","        }, \n","\n","        'monitor': {\n","          'values' : [ 'loss', 'val_loss' ]\n","        },\n","\n","        'layer': {\n","            'values': [ 0,1,2,3 ] \n","        },\n","\n","        'sqr': {\n","            'values': [ 1, 2 ] \n","        },\n","\n","        'nodes': {\n","            'values': [ 250 ] \n","        },\n","\n","        'pct_profit': {\n","            'values': [ 'pred_move', 'pred_moe_move' ] \n","        },\n","\n","        'features': {\n","            'values':  list_features\n","        },\n","\n","        'train': {\n","            'value': 7*1\n","        },\n","\n","        'tes': {\n","            'value':  1 \n","        }\n","\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmTkfqSDyT05"},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLE_CODE\"] = \"True\"\n","os.environ[\"WANDB_AGENT_MAX_INITIAL_FAILURES\"] = '1000'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYRIJ8DeXobl","outputId":"5abfedf4-4c27-4be4-841c-569aa4deeb4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Create sweep with ID: z3teakea\n","Sweep URL: https://wandb.ai/codechrl/my-sweep-test-project/sweeps/z3teakea\n"]}],"source":["# b5cfb2c82b057d3f137a7c529534bd0997ae4d3c\n","sweep_id = wandb.sweep(sweep_config, project=\"my-sweep-test-project\", entity=\"codechrl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VlF39yghXoeG","outputId":"cfeef421-3864-4e0f-caf6-756cdb193da9","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xsw62e6j with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: elu\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 168\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfeatures: ['low', 'trades', 'volume', 'move']\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tflatten: True\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_lr: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer: 0\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlook_back: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_func: huber_loss\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_decay: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmode: GRU\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmonitor: loss\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnodes: 250\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adadelta\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tpca: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tpct_profit: pred_move\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tregularizer: l1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tsqr: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttes: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain: 7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcodechrl\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","/home/kurniawan/anaconda3/envs/keras_gpu/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n","  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.11"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/kurniawan/jupyter/wandb/run-20220401_112901-xsw62e6j</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/codechrl/my-sweep-test-project/runs/xsw62e6j\" target=\"_blank\">clean-sweep-1</a></strong> to <a href=\"https://wandb.ai/codechrl/my-sweep-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/codechrl/my-sweep-test-project/sweeps/z3teakea\" target=\"_blank\">https://wandb.ai/codechrl/my-sweep-test-project/sweeps/z3teakea</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">clean-sweep-1</strong>: <a href=\"https://wandb.ai/codechrl/my-sweep-test-project/runs/xsw62e6j\" target=\"_blank\">https://wandb.ai/codechrl/my-sweep-test-project/runs/xsw62e6j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20220401_112901-xsw62e6j/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Run xsw62e6j errored: NotImplementedError(\"Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\")\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run xsw62e6j errored: NotImplementedError(\"Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\")\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nxjkk2fg with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: elu\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 168\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfeatures: ['open', 'high', 'pct_change', 'profit']\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tflatten: True\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_lr: 0.01\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlook_back: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_func: mean_absolute_percentage\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_decay: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmode: GRU\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmonitor: loss\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnodes: 250\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adadelta\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tpca: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tpct_profit: pred_moe_move\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tregularizer: l2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tsqr: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttes: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain: 7\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.11"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/kurniawan/jupyter/wandb/run-20220401_112918-nxjkk2fg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/codechrl/my-sweep-test-project/runs/nxjkk2fg\" target=\"_blank\">lively-sweep-2</a></strong> to <a href=\"https://wandb.ai/codechrl/my-sweep-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/codechrl/my-sweep-test-project/sweeps/z3teakea\" target=\"_blank\">https://wandb.ai/codechrl/my-sweep-test-project/sweeps/z3teakea</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">lively-sweep-2</strong>: <a href=\"https://wandb.ai/codechrl/my-sweep-test-project/runs/nxjkk2fg\" target=\"_blank\">https://wandb.ai/codechrl/my-sweep-test-project/runs/nxjkk2fg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20220401_112918-nxjkk2fg/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Run nxjkk2fg errored: NotImplementedError(\"Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\")\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run nxjkk2fg errored: NotImplementedError(\"Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\")\n","\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"]}],"source":["#sweep_id = 'igvj5e7z'\n","wandb.agent(sweep_id, function = train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJgfwUJ-yT1A"},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruvQxiI28MMS"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Sweep_v2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"}},"nbformat":4,"nbformat_minor":0}